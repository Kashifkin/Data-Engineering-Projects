import dlt

sales_rules = {
    "rule_1" : "sales_id IS NOT NULL"
}

# Create the streaming table (NOT a decorator)
dlt.create_streaming_table(
    name="sales_stg",
    expect_all_or_drop=sales_rules
)



@dlt.append_flow(target="sales_stg")
def east_sales():
    return spark.readStream.table("pyspark.source.sales_east")


@dlt.append_flow(target="sales_stg")
def west_sales():
    return spark.readStream.table("pyspark.source.sales_west")
